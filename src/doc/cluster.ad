= High Availability Cluster

In this section we explain how to configure, use, and administer Stardog Cluster
for uninterrupted operations. Stardog Cluster is a collection of Stardog Server
instances running on one or more virtual or physical machines that, *from the
client's perspective*, behave like a single Stardog Server instance. To fully
achieve this effect requires DNS (i.e., with `SRV` records) and proxy
configuration that's left as an exercise for the user. Of course Stardog Cluster
should have some different operational properties, the main one of which is high
availability. But from the client's perspective Stardog Cluster should be
indistinguishable from non-clustered Stardog.footnote:["Client" here means the
client of Stardog APIs.]

NOTE: High Availability requires *at least* three Stardog and three ZooKeeper
nodes in the Cluster. ZooKeeper works best, with respect to fault resiliency,
with an ensemble size that is an odd-number greater than or equal to three: 3,
5, 7, etc.footnote:["Because ZooKeeper requires a majority, it is best to use an
odd number of machines. For example, with four machines ZooKeeper can only
handle the failure of a single machine; if two machines fail, the remaining two
machines do not constitute a majority. However, with five machines ZooKeeper can
handle the failure of two machines." See
https://zookeeper.apache.org/doc/r3.1.2/zookeeperAdmin.html[Zk Admin] for more.]
With respect to performance, larger cluster sizes (Stardog and ZooKeeper)
perform better than smaller ones for reads, while larger cluster sizes perform
worse for writes. It is responsibility of the administrator to find the right
balance.

== Guarantees

Stardog Cluster implements an atomic commitment protocol based on
http://en.wikipedia.org/wiki/Two-phase_commit_protocol[two-phase commit (2PC)]
over a shared replicated memory that's provided by Apache ZooKeeper. A cluster
is composed of a set of Stardog servers and a ZooKeeper ensemble running
together. One of the Stardog servers is the Coordinator and the others are
Participants.

In case the Coordinator fails at any point, a new Coordinator will be elected
out of the remaining available Participants. Stardog Cluster supports both
`read` (e.g., querying) and `write` (e.g., adding data) requests. All read and
write requests can be handled by any of the nodes in the cluster. 
When a client commits a transaction (containing a list of `write` requests), it
will be acknowledged by the receiving node only
**after every non-failing peer node has committed the transaction**. If a peer node
fails during the process of committing a transaction, it will be expelled from the
cluster by the Coordinator and put in a temporary `failed` state. If the
Coordinator fails during the process, the transaction will be aborted. At that point 
the client can retry the transaction and it should succeed with the new cluster
coordinator.

Since `failed` nodes are not used for any subsequent `read` or `write` requests,
**if a commit is acknowledged, then Stardog Cluster
guarantees that the data has been accordingly modified at *every* available node in
the cluster**.

While this approach is less performant with respect to write
operations than eventual consistency used by other distributed databases,
typically those databases offer a much less expressive data model than Stardog,
which makes an eventually consistency model more appropriate for those systems (and less so for Stardog).
But since Stardog's data model is not only richly expressive but rests in part
on provably correct semantics, we think that a strong consistency model is worth
the cost.footnote:[Based on customer feedback we may relax these consistency
guarantees in some future release. Please get in touch if you think an
eventually consistent approach is more appropriate for your use of Stardog.]

== Single Server Migration

It is assumed that Stardog nodes in a Stardog Cluster are always going to be
used within a cluster context. Therefore, if you want to migrate from a Stardog
instance running in single server mode to running in a cluster, it is advised
that you create backups of your current databases and then import them to the
cluster in order to be able to provide the guarantees explained above. If you
simply add a Stardog instance to cluster that was previously running in single
server mode, _it will sync to the state of the cluster_; local data could be
removed when syncing with the cluster state.

== Configuration

To deploy Stardog Cluster you use `stardog-admin` commands and some
additional configuration. Stardog Cluster depends on Apache ZooKeeper.

You may be able to use `stardog-admin cluster generate` to bootstrap a cluster
configuration and, thus, to ease installation by simply passing a list of
hostnames or IP addresses for the cluster's nodes.

[source,bash]
----
$ stardog-admin cluster generate --output-dir /home/stardog 10.0.0.1 10.0.0.2 10.0.0.3
----

See the link:/man/cluster-generate.html[man page] for the details.

In a production environment we strongly recommend that each ZooKeeper process
runs in a different machine and, if possible, that ZooKeeper has a separate
drive for its data directory. If you need a larger cluster, adjust
accordingly.

In the following example we will set up a cluster with total of 6 nodes.
Zookeeper will be deployed on nodes 1-3 whereas Stardog will be deployed on
nodes 4-6.

. <<Quick Start Guide,Install>> Stardog {version} on each machine in the cluster.
+
NOTE: The best thing to do here, of course, is to use whatever infrastructure
you have in place to automate software installation. Adapting Stardog
installation to Chef, Puppet, cfengine, etc. is left as an exercise for the
reader.
+
. Make sure a valid Stardog license key (whether Developer, Enterprise, or a
30-day eval key) for the size of cluster you're creating exists and resides in
`STARDOG_HOME` on each node. You must also have a `stardog.properties` file with
the following information **for each Stardog node in the cluster**:
+
[source,bash]
----
# Flag to enable the cluster, without this flag set, the rest of the properties have no effect
pack.enabled=true
# this node's IP address (or hostname) where other Stardog nodes are going to connect
# this value is optional but if provided it should be unique for each Stardog node
pack.node.address=196.69.68.4
# the connection string for ZooKeeper where cluster state is stored
pack.zookeeper.address=196.69.68.1:2180,196.69.68.2:2180,196.69.68.3:2180
----
+
`pack.zookeeper.address` is a ZooKeeper connection string where cluster stores its
state. `pack.node.address` is not a required property.  The local address of the node, by default,
is `InetAddress.getLocalhost().getAddress()`, which should work for many deployments.  However if you're
using an atypical network topology and the default value is not correct, you can provide a value for this
property.
+
. Create the ZooKeeper configuration for each Zookeeper node. This config file is just a standard 
ZooKeeper configuration file and the same config file can be used for all Zookeeper nodes. The 
following config file should be sufficient for most cases. 
+
[source,bash]
----
tickTime=3000
# Make sure this directory exists and
# ZK can write and read to and from it.
dataDir=/data/zookeeperdata/
clientPort=2180
initLimit=5
syncLimit=2
# This is an enumeration of all Zk nodes in
# the cluster and must be identical in
# each node's config.
server.1=196.69.68.1:2888:3888
server.2=196.69.68.2:2888:3888
server.3=196.69.68.3:2888:3888
----
+
NOTE: The `clientPort` specified in `zookeeper.properties` and the ports used in `pack.cluster.address` in
`stardog.properties` must be the same.
+
. `dataDir` is where ZooKeeper persists cluster state and where it
writes log information about the cluster.
+
[source,bash]
----
$ mkdir /data/zookeeperdata # on node 1
$ mkdir /data/zookeeperdata # on node 2
$ mkdir /data/zookeeperdata # on node 3
----
+
. ZooKeeper requires a `myid` file in the `dataDir` folder to identify itself, you will create that file as follows
for `node1`, `node2`, and `node3`, respectively:
+
[source,bash]
----
$ echo 1 > /data/zookeeperdata/myid # on node 1
$ echo 2 > /data/zookeeperdata/myid # on node 2
$ echo 3 > /data/zookeeperdata/myid # on node 3
----

== Installation

In the next few steps you will use the Stardog Admin CLI commands to deploy
Stardog Cluster: that is, ZooKeeper and Stardog itself. We'll also configure
HAProxyfootnote:[There's nothing special about HAProxy here; you could implement
this proxy functionality in many different ways. We use HAProxy because it's
relatively easy and ubiquitous. YMMV.] as an example of how to use of Stardog
Cluster behind a proxy for load-balancing and fail-over capability.

. *Start ZooKeeper instances*
+
First, you need to start ZooKeeper nodes. You can do this using the standard 
command line tools that come with ZooKeeper. As a convenience, we provide a 
`stardog-admin cluster zkstart` subcommand that you can use to start ZooKeeper
instances:
+
[source,bash]
----
$ ./stardog-admin cluster zkstart --home ~/stardog # on node 1
$ ./stardog-admin cluster zkstart --home ~/stardog # on node 2
$ ./stardog-admin cluster zkstart --home ~/stardog # on node 3
----
+
This uses the `zookeeper.properties` config file in `~/stardog` and log its
output to `~/stardog/zookeeper.log`. If your `$STARDOG_HOME` is set to `~/stardog`,
then you don't need to specify the `--home` option. For more info about the command:
+
[source,bash]
----
$ ./stardog-admin help cluster zkstart
----
+
. *Start Stardog instances*
+
Once ZooKeeper is started, you can start Stardog instances:
+
[source,bash]
----
$ ./stardog-admin server start --home ~/stardog --port 5821 # on node 4
$ ./stardog-admin server start --home ~/stardog --port 5821 # on node 5
$ ./stardog-admin server start --home ~/stardog --port 5821 # on node 6
----
+
**Important:** When starting Stardog instances for the cluster, unlike single server 
mode, you need to provide the credentials of a superuser that will be used for 
securing the data stored in ZooKeeper and for intra-cluster communication. Each node
should be started with the same superuser credentials. By default, Stardog comes with
a superuser `admin` that has password `"admin"` and that is the default credentials
used by the above command. For a secure installation of Stardog cluster you should
change these credentials and restart the cluster with new credentials.
+
And again, if your `$STARDOG_HOME` is set to `~/stardog`, you don't need to specify
the `--home` option.
+
NOTE: Make sure to allocate roughly twice as much heap for Stardog than you would normally
do for single-server operation since there can be an additional overhead involved for
replication in the cluster. Also, we start Stardog here on the non-default port
(`5821`) so that you can use a proxy or load-balancer in the same machine which can
run on the default port (`5820`), meaning that Stardog clients can act normally (i.e.,
use the default port, `5820`) since they need to interact with HAProxy.
+
. *Start HAProxy*
+
In most Unix-like systems, HAProxy is available via package managers, e.g. in Debian-based systems:
+
[source,bash]
----
$ sudo apt-get update
$ sudo apt-get install haproxy
----
+
At the time of this writing, this will install HAProxy 1.4. You can refer to the
http://www.haproxy.org/[official site] to install a later release.
+
Place the following configuration in a file (such as `haproxy.cfg`) in order to
point HAProxy to the Stardog Cluster.
+
[source,text]
----
global
    daemon
    maxconn 256

defaults
    # you should update these values to something that makes
    # sense for your use case
    timeout connect 5s
    timeout client 1h
    timeout server 1h

# where HAProxy will listen for connections
frontend stardog-in
    option tcpka # keep-alive
    bind *:5820
    default_backend stardogs

# the Stardog servers
backend stardogs
    option tcpka # keep-alive
    # the following line performs a health check
    # HAProxy will check that each node accepts connections and
    # that it's operational within the cluster. Health check 
    # requires that Stardog nodes do not use --no-http option
    option httpchk GET /admin/healthcheck
    # replace these IP addresses with the corresponding node address
    # maxconn value can be upgraded if you expect more concurrent
    # connections
    server stardog1 196.69.68.1:5821 maxconn 64 check
    server stardog2 196.69.68.2:5821 maxconn 64 check
    server stardog3 196.69.68.3:5821 maxconn 64 check
----
+
If you wish to operate the cluster in HTTP-only mode, you can add the
`mode http` to backend settings.
+
Finally,
+
[source,bash]
----
$ haproxy -f haproxy.cfg
----
+
For more info on configuring HAProxy please refer to the http://www.haproxy.org/#docs[official
documentation]. In production environments we recommend running multiple proxies
to avoid single point of failures, and use DNS solutions for fail-over.
+
Now Stardog Cluster is running on 3 nodes, one each on 3 machines. Since
HAProxy was conveniently configured to use port `5820` you can execute
standard Stardog CLI commands to the Cluster:
+
[source,bash]
----
$ ./stardog-admin db create -n myDb
$ ./stardog data add myDb /path/to/my/data
$ ./stardog query myDb "select * { ?s ?p ?o } limit 5"
----

== Shutdown

In order to shut down the cluster you only need to execute the following command once:

[source,bash]
----
$ ./stardog-admin cluster stop
----

The `cluster stop` request will cause all available nodes in the cluster to shutdown. If a node
was expelled from the cluster due to a failure it would not receive this command and might need 
to be shutdown manually. In order to shutdown a single node in the cluster use the regular
`server stop` command and be sure to specify the server address:

[source,bash]
----
$ ./stardog-admin --server snarl://localhost:5821 server stop
----

If you send the `server stop` command to the load balancer then **a random node selected by the
load balancer will shutdown.** 

In addition to the Stardog cluster you still need to shut down ZooKeeper independently. Refer to
ZooKeeper documentation for details.

.Running Stardog Cluster on a Single Machine
****
For testing, development, or other purposes it may be advantageous to run
Stardog Cluster on a single machine. Of course this won't provide much actual
high availability, but it may be a reasonable choice in some cases.

The following changes must be made to the multi-machine configuration and
installation described previously:

[horizontal]
Stardog configuration::

* different `STARDOG_HOME` for each node
* different Stardog port for each node; the easiest setup is if no Stardog listens on port `5820`
* at least one (but no more than one) proxy on port `5820`
* different Watchdog port for each node via `watchdog.port` in `stardog.properties`

ZooKeeper configuration::

* different, that is, non-overlapping port ranges for each node
* different data directory for each node (e.g., different subdirectories in `/data/zookeeperdata`)

****

== Configuration Issues

=== Topologies & Size

In the configuration instructions above, we assume a particular Cluster
topology, which is to say, for each node `n` of a cluster, we run Stardog,
ZooKeeper, and HAProxy. But this is not the only topology supported by Stardog
Cluster. ZooKeeper nodes run independently, so other topologies--three ZooKeeper
servers and five Stardog servers are possible--you just have to point Stardog to
the corresponding ZooKeeper ensemble.

To add more Stardog Cluster nodes, simply repeat the steps for Stardog on
additional machines. Generally, as mentioned above, Stardog Cluster size should
be an odd number greater or equal to 3.

WARNING: ZooKeeper uses a very write heavy protocol; having Stardog and ZooKeeper
both writing to the *same* disk can yield contention issues, resulting in
timeouts at scale. We recommend at a minimum having the two services writing to
separate disks to reduce contention or, ideally, have them run on separate nodes
entirely.

=== Open File Limits

If you expect to use Stardog Cluster with heavy concurrent write workloads, then
you should probably increase the number of open files that host OS will permit
on each Cluster node. You can typically do this on a Linux machine with `ulimit
-n` or some variant thereof. Because nodes communicate between themselves and
with ZooKeeper, it's important to make sure that there are sufficient file
handle resources available.footnote:[This point is especially true of Cluster
but may be relevant for some workloads on a single Stardog database, that
is, non-Cluster configuration, too.]

=== Connection/Session Timeouts

Stardog nodes connect to the ZooKeeper cluster and establishes a 
https://zookeeper.apache.org/doc/trunk/zookeeperProgrammers.html#ch_zkSessions[session]. 
The session is kept alive by PING requests sent by the client. If the Stardog 
node does not send these requests to the ZooKeeper server (due to network issues,
node failure, etc.) the session will timeout and the Stardog node will get into 
a suspended state and it will reject any queries or transactions until it can 
establish the session again.

If a Stardog node is overloaded then it might fail to send the PING requests
to ZooKeeeper server in a timely manner. This usually happens when Stardog's
memory usage is close to the limit and there are frequent GC pauses. This 
would cause Stardog nodes to be suspended unnecessarily. In order to prevent
this problem make sure Stardog nodes have enough memory allocated and tweak
the timeout options.

There are two different configuration options that control timeouts for the
ZooKeeper server. The `pack.connection.timeout` option specifies the max time 
that Stardog waits to establish a connection to ZooKeeper. The `pack.session.timeout`
option specifies the session timeout explained above. You can set these values
in `stardog.properties` as follows:

[source,bash]
----
pack.connection.timeout=15s
pack.session.timeout=60s
----

Note that, ZooKeeper has limitations about how these values can be set based on 
the `tickTime` value specified in the ZooKeeper configuration file. Session
timeout needs to be a minimum of 2 times the `tickTime` and a maximum of 20 times 
the `tickTime`. So a session timeout of `60s` requires the `tickTime` to be at 
least `3s` (in ZooKepeer configuration file this value should be entered in 
milliseconds). If the session timeout is not in the allowed range the ZooKeeper 
will negotiate a new timeout value and Stardog will print a warning about this
in the `stardog.log` file.


=== Client Usage

To use Stardog Cluster with standard Stardog clients and CLI tools in the
ordinary way--`stardog-admin` and `stardog`--you must have Stardog installed
locally. With the provided Stardog binaries in the Stardog Cluster distribution
you can query the state of Cluster:

[source,bash]
----
$ ./stardog-admin --server snarl://<ipaddress>:5820/ cluster info
----

where `ipaddress` is the IP address of any of the nodes in the cluster. This
will print the available nodes in the cluster, as well as the roles (participant
or coordinator). You can also input the proxy IP address and port to get the
same information.

To add or remove data, issue `stardog data add` or `remove` commands to
any node in the cluster. Queries can be issued to any node in the cluster using
the `stardog query` command. All the `stardog-admin` features are also available
in Cluster, which means you can use any of the commands to create
databases, administer users, and the rest of the functionality.
